---
title: "Boostcamp AI Tech (Day 057)"
date: 2024-11-12
layout: post
tags: [Naver Boostcamp, daily report]
---
![ai tech blog](https://bohyun-mu.vercel.app/4-projects/semantic-seg/24-11-12/)
 아침운동 1시간 ✅ 2024-11-12
 과제 기본1
 과제 기본2
 과제 기본3
 🔺 강의다듣기 ✅ 2024-11-13
 6,7강 퀴즈풀기 ✅ 2024-11-12
 7강듣기 ✅ 2024-11-12
 8강듣기 ✅ 2024-11-12
 8강 퀴즈풀기 ✅ 2024-11-12
 알고리즘스터디 2시 ✅ 2024-11-12
 멘토링3시 ✅ 2024-11-12
 9강듣기 ✅ 2024-11-12
 10강듣기 ✅ 2024-11-13
7~8강에서 대회에 사용하는 모델과 테크닉들을 위주로 강의
7강 Semantic Segmentation 대회에서 사용하는 방법들 1
- EfficientUnet baseline
- baseline 이후에 실험 해봐야할 사항들

Augmentation
Cutout


우리가 원하는건 fig1이지만 fig2처럼 객체를 너무 일부만 가리거나 fig3처럼 객체를 아예 다 가려버릴수도 있다.

이 문제점을 해결하기 위해 Gridmask라는 기법이 존재한다.

Albumentations 내 클래스 명이 GridDropout이다.




Mixup

이미지를 x1,x2라고 하자

람다 만큼의 비율로 x1과 x2를 섞어주게 된다.

out과 label간의 차이를 비교해서 loss를 계산하는게 mixup의 핵심이다.

Cutmix


일부 영역은 x2에서 가져오고 일부 영역은 x1에서 가져온다.

코드를 보면 먼저 얼마만큼 크기의 박스로 자를지 결정을 해준다.
w * cut_ratio, 등등
얼마만큼의 크기로 자를지 결정해주면, 이제 크기를 결정을 해주어야 한다.

그 부분을 담당하는게 cx와 cy다.
cy와 cy를 중심으로 위치를 결정하고 해당 영역을 중심으로 아까 결정했던 w와 h를

np.clip같은 함수는 잘리는 박스가 이미지 밖으로 넘어가지 않도록 해준다.


원본이미지에 랜덤index를 가져와서 아래와 같은 결과가 된다.

이제 loss 계산을 해주어야 하는데,
1-람다와 바뀐 타겟 b인 종이상자와 곱해준다.


SnapMix

CAM을 이용해 이미지의 중요한 영역을 잘라서 그 부분을 교체하는 기법

CropNonEmptyMaskIfExists

중요한 부분을 학습한다.

Scheduler

scheduler를 통해 빠른 속도로 수렴 가능하고 높은 정확도를 가진다.

CosineAnnealingLR: saddle point 정체구간을 빠르게 벗어나게하는 장점이 있다.


ReduceLROnPlateau

IoU와 loss등으로 확인할 수 있다.

Gradual Warmup: 마스터님이 가장 많이 사용하신다고 한다.
기존 가중치(pretrained)에 대해 불안정한 초반에도 비교적 안정적인 학습을 해서 training process가 안정될 때 까지 기다린다.


Optimizer / Loss


Lookahead optimizer

global optimal point에 다가가게 해준다.

하이브리드 형태의 Loss도 이용가능하다.
꼭 참고해서 사용해보자!

8강 Semantic Segmentation 대회에서 사용하는 방법들 2
- baseline 이후에 실험 해봐야할 사항들 II
- 대회에서 사용하는 기법들 소개
- Monitoring Tool

Ensemble
SWA 스와 (Stochastic Weight Averaging)

설정한 epoch 이후부터 SWA start



큰객체,작은객체,중간객체 잘 찾는 모델들간의 시너지를 알아볼 수 있는 앙상블!

TTA

inference할 때 입력이미지만 augmentation 해준다.
장점은 k-fold등 모델 여러번 학습해야했던 애들이랑 다르게 train모델은 그대로 쓰고 test시에 inference시간만 조금 늘어나서 좋다.
주의해야할 점은 1. 어떤 augmentation사용해야할지(학습에 사용했던거 사용하면 좋겠죠?) 2. 몇번이나 augmentation 진행할지 3. 가중치


TTA Library인 ttach를 활용할 수 있다.

2x2x3 = 12가지 TTA가 가능하다..

단순 앙상블 하는게 아니라 모델 Inference결과를 본다든지.. 해야함

각자 레이블이라는 의미
보통 test data에 대해 수도 레이블을 만듦
train을 t/v로 나누는데

1,4번은 큰 확신을 가지고 예측을 했고 2,3번은 비교적 덜 확신했다.


외부 데이터 활용
Classification 결과 활용


최근 딥러닝 이미지 대회 Trend

데이터 크기가 커지고 양이 많아졌다.
문제점1. 학습하는데 시간이 오래 걸려서 충분한 실험을 하지 못한다.


Solution 1-1 Mixed-Precision Training
scaler로 AMP활용시 발생할 수 있는 underflow 문제 방지



FP16 외에도 실험을 간소화 시킬 수 있다.

가벼운 상황으로 실험

실험은 hold-out으로하고 제출은 K-fold로 하는 기법 사용!
단, 이때 신뢰성이 낮아지는걸 줄이기 위해서

리더보드와 validation score간의 어느 정도 상관관계가 있는지 실험 하는게 k-fold말고도 의미가 있다는걸 증명해야함

여기서 볼 수 있는 점은 실험은 간소하게 진행해서 의미있는 결과를 내고,
최종에 가서 다 적용한 모습을 볼 수 있다.


정보량을 풍부하게 만드는 기법

가벼운 모델로 실험할 필요성도 있다.

Resize

1024 1024fmf 256 256으로 학습과 inference한다음에 보간을 해서 1024 1024로 복원하기
근데 주의해야할점은

허브맵의 경우 초록색의 벽면을 예측하는 부분이 35000x25000이였는데 resolution이 감소해서 학습과 예측이 잘 안되는 경우도 발생했다.
이러한 문제를 해결하기 위해 생각해볼 수 있는게

stride size보다 큰 경우는 중복되는 영역이 발생한다. 계속해서 중복하는 영역이 발생한다.


window사이즈가 같은 경우에는 겹치지 않는다.

두 경우에 어떤 장단점이 있을까?


이렇게 window 사이즈가 작으면 부족하고 한정된 정보를 받을 수 있는데,

window사이즈가 크면 풍부한 정보를 받을 수 있는 장점이 있고

stride 사이즈를 작게 했을 때 어떤 장점이 있는지 생각해보면
stride 사이즈를 줄였기 때문에 input image 수가 늘어나는 장점이 있다.

또 위의 빨간색 두개로 잘랐을땐 왼쪽하나, 오른쪽하나 두가지 case밖에 못봤을텐데
input image 수를 늘림으로써 다양한 상황에 대해서 생각을 해볼 수 있다.


필요한 정보를 포함시킬 수 있고 앙상블해서 성능 향상을 얻을 수 있다는 장점이 있다.

반대로 단점도 존재하는데

데이터가 늘어났지만 그 늘어난 데이터들 간에 상관성이 높다.

팁이 있는데 반드시 train과 inference의 사이즈를 같게 할 필요는 없다.

실제로 inference에서 이미지가 커지면 더 많은 주변 정보를 통해서 성능의 정확도가 올라가는 경우가 경험적으로 많았다.

두번째론 kaggle 허브맵에 나온거처럼 슬라이딩 윈도우를 적용할 때 샘플링을 적용할 수도 있다.

의미 없는 배경만 훑다보면 시간도 오래걸리고 불필요한 영역이 많으니까 이런 부분들을 줄여서 학습 속도를 개선할 수 있지 않을까? 생각해서 활용된 기법이

박스친 부분에 병변이 있으면 GOOD 없으면 Try Again해서 이 파트는 학습 속도 상승 효과가 있었다.

center crop
세번째 팁으로는 sliding window할 때 object의 가장자리만 나오는 경우(의미가 적고 예측하기 어려움

object가 제대로 나온 center만 crop해서 이용하는 edge removed 라는 tech

활용가능성이 높은 tip!!

Threshold
주로 threshold를 0.5로 하지만 이게 꼭 정답이 아닐 수 있다.

어떤 카테고리는 0.5, 어떤 카테고리는 0.6 이런식으로 카테고리별로 threshold를 다르게 할 수도 있다.

Model 개선 Tip
validation, output의 inference된 이미지를 input image, segmentation과 비교해보면서 어떤 점을 잘하고 있고 어떤 점을 못하고 있는지를 살펴보는게 중요하다!
(validation이 레이블이 있으니까 좀 더 비교하기 편하겠죠?)

배경부터 클래스까지 잘하고있는 못하고있는 클래스들을 구분해서
어떤 클래스에 대해서(못하는) 약점을 보완해서 성능을 향상시킬 방법을 고안하자!

Label Noise가 있는 경우


Label smoothing

타겟을 바꿔서 loss를 바꿈

fold가 5라고 했을 때,
전체 train set에대한 전체 이미지에 대한 실제 label

IoU가 낮은 케이스에 대해서 입력이미지를 일부 버리는 전처리를 할 수도 있고

낮은 IoU에 대해서는 Nosed GT를 활용하는게 아니라 다시 GT를 활용해서 train을 다시 하게되면

기존의 noise한거 학습한거 대비 성능이 개선될 가능성을 볼 수 있다.
요즘 대회 trend를 보면 accuracy, mIoU등의 다양한 평가 방식을 추가한다.

Epcoh앙상블 (다양한 weight 수집)
TTA (위에서 수집한 weight를 앙상블)
Monitoring
웹상에 기록하면 비교와 기록에 용이함

9~10강은 최근 세그멘테이션 연구동향
 9강은 SOTA 모델인 HRNet과 SegFormer - HRNet으로 Cityscape 데이터에서는 좋은 성능을 달성하고 있는 네트워크

9강 Semantic Segmentation 연구 동향 1
9강

HRNet의 필요성
HRNet 구조 살펴보기
HRNet의 세부 구조 및 구현
HRNet의 실험 결과
9.1강

최근 Semantic Segmnetation 연구 동향
SegFormer 구조 살펴보기
SegFormer 세부 구조 및 구현
SegFormer의 실험 결과
HRNet



SegFormer





10강은 Weakly Supervised Semantic Segmentation 분야 - 회와는 크게 상관이 없지만 실제 Application 측면에서 강의

10강 Semantic Segmentation 연구 동향 2
WSSS 개요
CAM 기반의 접근
WSSS History